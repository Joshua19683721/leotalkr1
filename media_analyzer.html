<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 多媒體分析助手 (Nemotron-12B)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        .markdown-body {
            font-family: -apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji";
            line-height: 1.6;
            color: #24292e;
        }
        .markdown-body h1, .markdown-body h2, .markdown-body h3 { margin-top: 24px; margin-bottom: 16px; font-weight: 600; line-height: 1.25; }
        .markdown-body h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: .3em; }
        .markdown-body h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: .3em; }
        .markdown-body p { margin-top: 0; margin-bottom: 16px; }
        .markdown-body code { padding: .2em .4em; margin: 0; font-size: 85%; background-color: #f6f8fa; border-radius: 6px; }
        .markdown-body pre { padding: 16px; overflow: auto; font-size: 85%; line-height: 1.45; background-color: #f6f8fa; border-radius: 6px; }
        .markdown-body ul, .markdown-body ol { padding-left: 2em; margin-bottom: 16px; }
        .markdown-body blockquote { padding: 0 1em; color: #6a737d; border-left: 0.25em solid #dfe2e5; margin: 0 0 16px 0; }
        
        .loading-spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #3b82f6;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-gray-50 min-h-screen p-4 md:p-8">

    <div class="max-w-4xl mx-auto bg-white rounded-xl shadow-lg overflow-hidden">
        
        <!-- Header -->
        <div class="bg-gradient-to-r from-blue-600 to-indigo-700 p-6 text-white">
            <h1 class="text-3xl font-bold">AI 多媒體深度解析助手</h1>
            <p class="mt-2 opacity-90">使用 nvidia/nemotron-nano-12b-v2-vl:free 模型進行圖像與影片分析</p>
        </div>

        <div class="p-6 space-y-6">
            
            <!-- Settings Section -->
            <div class="bg-gray-50 p-4 rounded-lg border border-gray-200">
                <h2 class="text-lg font-semibold mb-3 text-gray-700 flex items-center">
                    <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10.325 4.317c.426-1.756 2.924-1.756 3.35 0a1.724 1.724 0 002.573 1.066c1.543-.94 3.31.826 2.37 2.37a1.724 1.724 0 001.065 2.572c1.756.426 1.756 2.924 0 3.35a1.724 1.724 0 00-1.066 2.573c.94 1.543-.826 3.31-2.37 2.37a1.724 1.724 0 00-2.572 1.065c-.426 1.756-2.924 1.756-3.35 0a1.724 1.724 0 00-2.573-1.066c-1.543.94-3.31-.826-2.37-2.37a1.724 1.724 0 00-1.065-2.572c-1.756-.426-1.756-2.924 0-3.35a1.724 1.724 0 001.066-2.573c-.94-1.543.826-3.31 2.37-2.37.996.608 2.296.07 2.572-1.065z"></path><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z"></path></svg>
                    設定
                </h2>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">OpenRouter API Key</label>
                        <input type="password" id="apiKey" placeholder="sk-or-..." class="w-full p-2 border border-gray-300 rounded focus:ring-2 focus:ring-blue-500 focus:border-blue-500 outline-none transition" value="">
                        <div class="flex items-center mt-2">
                            <input type="checkbox" id="saveKeyCheckbox" class="h-4 w-4 text-blue-600 focus:ring-blue-500 border-gray-300 rounded">
                            <label for="saveKeyCheckbox" class="ml-2 block text-sm text-gray-900">
                                記住 API Key (存於瀏覽器本地)
                            </label>
                        </div>
                    </div>
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">模型 (Model)</label>
                        <input type="text" id="modelName" value="nvidia/nemotron-nano-12b-v2-vl:free" class="w-full p-2 border border-gray-300 rounded bg-gray-100 text-gray-600" readonly>
                    </div>
                </div>
            </div>

            <!-- Webcam Section -->
            <div class="bg-gray-50 p-4 rounded-lg border border-gray-200">
                <h2 class="text-lg font-semibold mb-3 text-gray-700 flex items-center">
                    <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z"></path></svg>
                    即時攝影鏡頭 (Live Camera)
                </h2>
                <div class="space-y-4">
                    <div class="relative bg-black rounded-lg overflow-hidden aspect-video max-w-lg mx-auto">
                        <video id="webcamVideo" class="w-full h-full object-contain" autoplay playsinline muted></video>
                        <div id="cameraStatus" class="absolute top-2 right-2 bg-red-600 text-white text-xs px-2 py-1 rounded hidden animate-pulse">
                            ● 錄影中 (每30秒分析)
                        </div>
                    </div>
                    <div class="flex flex-wrap justify-center gap-4">
                        <button id="startCamBtn" class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-2 px-4 rounded transition">
                            開啟鏡頭
                        </button>
                        <button id="switchCamBtn" class="bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded transition hidden">
                            切換鏡頭
                        </button>
                        <button id="startLoopBtn" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-4 rounded transition disabled:opacity-50 disabled:cursor-not-allowed" disabled>
                            開始自動循環分析 (每30秒)
                        </button>
                        <button id="stopLoopBtn" class="bg-red-500 hover:bg-red-600 text-white font-bold py-2 px-4 rounded transition hidden">
                            停止循環
                        </button>
                    </div>
                    
                    <div class="flex items-center justify-center mt-2">
                        <label class="flex items-center cursor-pointer select-none">
                            <div class="relative">
                                <input type="checkbox" id="powerSavingCheckbox" class="sr-only peer">
                                <div class="w-11 h-6 bg-gray-200 peer-focus:outline-none rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:start-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-5 after:w-5 after:transition-all peer-checked:bg-green-600"></div>
                            </div>
                            <span class="ms-3 text-sm font-medium text-gray-700">省電模式 (暫停畫面渲染)</span>
                        </label>
                    </div>

                    <div id="countdownTimer" class="text-center text-gray-500 font-mono hidden">下次分析: <span id="timeLeft">30</span>s</div>
                </div>
            </div>

            <!-- Input Area -->
            <div class="space-y-4">
                <div class="border-2 border-dashed border-gray-300 rounded-xl p-8 text-center hover:bg-gray-50 transition relative" id="dropZone">
                    <input type="file" id="fileInput" class="hidden" accept="image/*,video/*" multiple>
                    <div class="space-y-2 pointer-events-none">
                        <svg class="mx-auto h-12 w-12 text-gray-400" stroke="currentColor" fill="none" viewBox="0 0 48 48"><path d="M28 8H12a4 4 0 00-4 4v20m32-12v8m0 0v8a4 4 0 01-4 4H12a4 4 0 01-4-4v-4m32-4l-3.172-3.172a4 4 0 00-5.656 0L28 28M8 32l9.172-9.172a4 4 0 015.656 0L28 28m0 0l4 4m4-24h8m-4-4v8m-12 4h.02" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" /></svg>
                        <p class="text-gray-600">點擊上傳，拖放文件，或直接 <span class="font-bold text-blue-600">貼上 (Ctrl+V)</span> 圖片</p>
                        <p class="text-xs text-gray-500">支援圖片 (JPG, PNG) 與 影片 (MP4, WebM)</p>
                    </div>
                </div>

                <div class="flex items-center space-x-2">
                    <span class="text-gray-500 text-sm font-medium">或輸入影片連結:</span>
                    <input type="url" id="urlInput" placeholder="https://example.com/video.mp4" class="flex-1 p-2 border border-gray-300 rounded focus:ring-2 focus:ring-blue-500 outline-none">
                    <button id="loadUrlBtn" class="bg-gray-200 hover:bg-gray-300 text-gray-700 px-4 py-2 rounded transition">載入連結</button>
                </div>
            </div>

            <!-- Preview Area -->
            <div id="previewArea" class="hidden space-y-4">
                <h3 class="text-md font-semibold text-gray-700">預覽內容</h3>
                <div id="mediaContainer" class="flex flex-wrap gap-4 justify-center bg-black/5 p-4 rounded-lg min-h-[100px] items-center">
                    <!-- Images/Videos will be injected here -->
                </div>
                <div id="videoFramesInfo" class="hidden text-sm text-blue-600 bg-blue-50 p-2 rounded">
                    <span class="font-bold">提示:</span> 已自動從影片中擷取關鍵影格用於分析。
                </div>
            </div>

            <!-- Action Area -->
            <button id="analyzeBtn" class="w-full bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg shadow-md hover:shadow-lg transform hover:-translate-y-0.5 transition duration-150 ease-in-out disabled:opacity-50 disabled:cursor-not-allowed">
                開始 AI 深度分析
            </button>

            <!-- Result Area -->
            <div id="resultSection" class="hidden">
                <div class="border-t border-gray-200 pt-6">
                    <h2 class="text-xl font-bold mb-4 text-gray-800 flex items-center">
                        <svg class="w-6 h-6 mr-2 text-blue-600" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path></svg>
                        分析結果
                    </h2>
                    <div id="loadingIndicator" class="hidden flex flex-col items-center justify-center py-8">
                        <div class="loading-spinner mb-4"></div>
                        <p class="text-gray-600 animate-pulse">正在調用大模型進行深度解讀，請稍候...</p>
                    </div>
                    <div id="outputContent" class="markdown-body bg-white p-6 rounded-lg border border-gray-200 shadow-sm min-h-[200px]">
                        <!-- Markdown result will appear here -->
                    </div>
                </div>
            </div>

        </div>
        
        <!-- Footer -->
        <div class="bg-gray-100 p-4 text-center text-gray-500 text-sm">
            Powered by OpenRouter & Nvidia Nemotron
        </div>
    </div>

    <!-- Hidden video element for frame extraction -->
    <video id="hiddenVideo" class="hidden" crossorigin="anonymous" playsinline muted></video>
    <canvas id="hiddenCanvas" class="hidden"></canvas>

    <script>
        // DOM Elements
        const apiKeyInput = document.getElementById('apiKey');
        const saveKeyCheckbox = document.getElementById('saveKeyCheckbox');
        const dropZone = document.getElementById('dropZone');
        const fileInput = document.getElementById('fileInput');
        const urlInput = document.getElementById('urlInput');
        const loadUrlBtn = document.getElementById('loadUrlBtn');
        const previewArea = document.getElementById('previewArea');
        const mediaContainer = document.getElementById('mediaContainer');
        const analyzeBtn = document.getElementById('analyzeBtn');
        const resultSection = document.getElementById('resultSection');
        const outputContent = document.getElementById('outputContent');
        const loadingIndicator = document.getElementById('loadingIndicator');
        const videoFramesInfo = document.getElementById('videoFramesInfo');
        const hiddenVideo = document.getElementById('hiddenVideo');
        const hiddenCanvas = document.getElementById('hiddenCanvas');
        const webcamVideo = document.getElementById('webcamVideo');
        const startCamBtn = document.getElementById('startCamBtn');
        const switchCamBtn = document.getElementById('switchCamBtn');
        const startLoopBtn = document.getElementById('startLoopBtn');
        const stopLoopBtn = document.getElementById('stopLoopBtn');
        const cameraStatus = document.getElementById('cameraStatus');
        const countdownTimer = document.getElementById('countdownTimer');
        const timeLeftSpan = document.getElementById('timeLeft');
        const powerSavingCheckbox = document.getElementById('powerSavingCheckbox');

        // State
        let mediaItems = []; // Array of { type: 'image'|'video', content: base64, originalFile: fileObj }
        let extractedFrames = []; // Array of base64 strings for analysis
        let autoLoopInterval = null;
        let countdownInterval = null;
        let ttsQueue = [];
        let ttsActive = false;
        let currentUtterance = null; // Prevent GC issues

        // Load API Key from local storage
        const savedKey = localStorage.getItem('openrouter_api_key');
        if (savedKey) {
            apiKeyInput.value = savedKey;
            saveKeyCheckbox.checked = true;
        }

        // Save API Key on change
        apiKeyInput.addEventListener('input', () => {
            if (saveKeyCheckbox.checked) {
                localStorage.setItem('openrouter_api_key', apiKeyInput.value);
            }
        });

        saveKeyCheckbox.addEventListener('change', () => {
            if (saveKeyCheckbox.checked) {
                localStorage.setItem('openrouter_api_key', apiKeyInput.value);
            } else {
                localStorage.removeItem('openrouter_api_key');
            }
        });

        // Event Listeners for Drag & Drop
        dropZone.addEventListener('click', () => fileInput.click());
        dropZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            dropZone.classList.add('bg-blue-50', 'border-blue-400');
        });
        dropZone.addEventListener('dragleave', () => {
            dropZone.classList.remove('bg-blue-50', 'border-blue-400');
        });
        dropZone.addEventListener('drop', (e) => {
            e.preventDefault();
            dropZone.classList.remove('bg-blue-50', 'border-blue-400');
            handleFiles(e.dataTransfer.files);
        });
        fileInput.addEventListener('change', (e) => handleFiles(e.target.files));

        // Paste Event
        document.addEventListener('paste', (e) => {
            const items = e.clipboardData.items;
            const files = [];
            for (let i = 0; i < items.length; i++) {
                if (items[i].type.indexOf('image') !== -1) {
                    files.push(items[i].getAsFile());
                }
            }
            if (files.length > 0) handleFiles(files);
        });

        // URL Load
        loadUrlBtn.addEventListener('click', () => {
            const url = urlInput.value.trim();
            if (url) processVideoUrl(url);
        });

        // Analyze Button
        analyzeBtn.addEventListener('click', startAnalysis);

        // Webcam Logic
        let currentStream = null;
        let videoDevices = [];
        let currentDeviceIndex = 0;

        async function startCamera(deviceId = null) {
            // Check support
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                alert("您的瀏覽器不支援攝影機存取，或因連線不安全 (非 HTTPS) 而被封鎖。\n\n如果您是透過 IP (如 192.168.x.x) 測試，請改用 localhost 或部署至 GitHub Pages (HTTPS)。");
                return;
            }

            // Stop current stream
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }

            // Helper to try getting stream
            const getStream = async (constraints) => {
                try {
                    return await navigator.mediaDevices.getUserMedia(constraints);
                } catch (e) {
                    console.warn("Constraint failed:", constraints, e);
                    return null;
                }
            };

            let stream = null;

            // 1. Try specific device if requested
            if (deviceId) {
                stream = await getStream({ video: { deviceId: { exact: deviceId } } });
            }
            
            // 2. If no specific device or it failed, try "environment" (rear camera)
            if (!stream && !deviceId) {
                stream = await getStream({ video: { facingMode: { ideal: "environment" } } });
            }

            // 3. If "environment" failed (or not requested), try ANY video camera (fallback)
            if (!stream) {
                stream = await getStream({ video: true });
            }

            if (!stream) {
                console.error("All camera attempts failed.");
                alert("無法啟動攝影機。請確認：\n1. 已允許攝影機權限\n2. 網址為 localhost 或 HTTPS (安全連線)\n3. 設備上有可用的攝影機");
                return;
            }

            // Success
            try {
                currentStream = stream;
                webcamVideo.srcObject = stream;
                
                // Important: play() must be called
                webcamVideo.onloadedmetadata = () => {
                    webcamVideo.play().catch(e => console.error("Auto-play failed:", e));
                };

                startCamBtn.classList.add('hidden');
                startLoopBtn.disabled = false;

                // Enumerate devices
                const devices = await navigator.mediaDevices.enumerateDevices();
                videoDevices = devices.filter(device => device.kind === 'videoinput');
                
                if (videoDevices.length > 1) {
                    switchCamBtn.classList.remove('hidden');
                    // Update index
                    const currentTrack = stream.getVideoTracks()[0];
                    const settings = currentTrack.getSettings();
                    const currentDeviceId = settings.deviceId;
                    
                    // Update current index
                    if (currentDeviceId) {
                        currentDeviceIndex = videoDevices.findIndex(d => d.deviceId === currentDeviceId);
                        if (currentDeviceIndex === -1) currentDeviceIndex = 0;
                    }
                }
            } catch (err) {
                console.error("Stream setup error:", err);
                alert("攝影機串流設定失敗: " + err.message);
            }
        }

        startCamBtn.addEventListener('click', async () => {
            await startCamera();
        });

        switchCamBtn.addEventListener('click', async () => {
            if (videoDevices.length < 2) return;
            currentDeviceIndex = (currentDeviceIndex + 1) % videoDevices.length;
            await startCamera(videoDevices[currentDeviceIndex].deviceId);
        });

        startLoopBtn.addEventListener('click', () => {
            startLoopBtn.classList.add('hidden');
            stopLoopBtn.classList.remove('hidden');
            cameraStatus.classList.remove('hidden');
            countdownTimer.classList.remove('hidden');

            // Apply power saving state immediately
            if (powerSavingCheckbox.checked) {
                webcamVideo.pause();
            }

            captureAndAnalyze();
            
            let timeLeft = 30;
            timeLeftSpan.innerText = timeLeft;
            
            countdownInterval = setInterval(() => {
                timeLeft--;
                timeLeftSpan.innerText = timeLeft;
                if (timeLeft <= 0) timeLeft = 30;
            }, 1000);

            autoLoopInterval = setInterval(() => {
                captureAndAnalyze();
                timeLeft = 30;
                timeLeftSpan.innerText = timeLeft;
            }, 30000);
        });

        stopLoopBtn.addEventListener('click', () => {
            stopLoopBtn.classList.add('hidden');
            startLoopBtn.classList.remove('hidden');
            cameraStatus.classList.add('hidden');
            countdownTimer.classList.add('hidden');
            
            clearInterval(autoLoopInterval);
            clearInterval(countdownInterval);
            autoLoopInterval = null;
            countdownInterval = null;

            // Resume video if it was paused by power saving
            if (webcamVideo.paused) {
                webcamVideo.play().catch(e => console.error("Resume failed:", e));
            }
        });

        async function captureAndAnalyze() {
            if (!webcamVideo.srcObject) return;

            // Flash effect
            webcamVideo.classList.add('opacity-50');
            setTimeout(() => webcamVideo.classList.remove('opacity-50'), 200);

            // Capture frame
            hiddenCanvas.width = webcamVideo.videoWidth;
            hiddenCanvas.height = webcamVideo.videoHeight;
            const ctx = hiddenCanvas.getContext('2d');
            ctx.drawImage(webcamVideo, 0, 0, hiddenCanvas.width, hiddenCanvas.height);
            const dataUrl = hiddenCanvas.toDataURL('image/jpeg', 0.8);

            // Reset state and prepare for single image analysis
            resetState();
            extractedFrames = [dataUrl];
            
            // We don't need to show preview for auto-loop, result is enough? 
            // Or maybe show the captured frame in preview area?
            // Let's show it so user knows what's being analyzed.
            mediaItems.push({ type: 'image', content: dataUrl });
            updatePreview();

            // Analyze
            await startAnalysis(true); // true = auto mode
        }

        // --- Core Functions ---

        async function handleFiles(files) {
            if (!files.length) return;
            
            // Clear previous items if single analysis mode (or keep appending? let's reset for simplicity)
            resetState();

            for (let file of files) {
                if (file.type.startsWith('image/')) {
                    await processImageFile(file);
                } else if (file.type.startsWith('video/')) {
                    await processVideoFile(file);
                }
            }
            updatePreview();
            
            // Auto-start analysis if API key is present
            if (apiKeyInput.value.trim()) {
                startAnalysis();
            }
        }

        function resetState() {
            clearTTS(); // Stop any ongoing speech immediately
            mediaItems = [];
            extractedFrames = [];
            mediaContainer.innerHTML = '';
            outputContent.innerHTML = '';
            resultSection.classList.add('hidden');
            videoFramesInfo.classList.add('hidden');
            previewArea.classList.add('hidden');
        }

        function processImageFile(file) {
            return new Promise((resolve) => {
                const reader = new FileReader();
                reader.onload = (e) => {
                    mediaItems.push({ type: 'image', content: e.target.result });
                    // For images, the content itself is what we send
                    extractedFrames.push(e.target.result); 
                    resolve();
                };
                reader.readAsDataURL(file);
            });
        }

        async function processVideoFile(file) {
            const url = URL.createObjectURL(file);
            await extractFramesFromVideo(url, true); // true = revoke url after
        }

        async function processVideoUrl(url) {
            resetState();
            // Check if it looks like a video file
            if (url.match(/\.(mp4|webm|ogg)$/i) || url.startsWith('blob:')) {
                await extractFramesFromVideo(url, false);
            } else {
                // Fallback: Just display it and hope the user knows the model might not see it unless we screen capture?
                // Actually, for YouTube etc, we can't easily get frames client side due to CORS.
                // We will treat it as a "Link Analysis" task if we can't load it.
                // But for now, let's try to load it in video tag.
                await extractFramesFromVideo(url, false);
            }
            updatePreview();

            // Auto-start analysis if API key is present
            if (apiKeyInput.value.trim()) {
                startAnalysis();
            }
        }

        async function extractFramesFromVideo(videoUrl, revokeUrl) {
            return new Promise((resolve, reject) => {
                // Handle CORS for local vs remote
                // python -m http.server does not support CORS headers by default, so requesting with crossorigin='anonymous'
                // for same-origin resources will fail because the server won't return the required ACAO header.
                // We should only use crossorigin if the domain is different.
                try {
                    const urlObj = new URL(videoUrl, window.location.href);
                    if (urlObj.origin === window.location.origin) {
                        hiddenVideo.removeAttribute('crossorigin');
                    } else {
                        hiddenVideo.setAttribute('crossorigin', 'anonymous');
                    }
                } catch (e) {
                    // If invalid URL (e.g. blob:), it's likely safe/local or handles itself
                    hiddenVideo.removeAttribute('crossorigin');
                }

                hiddenVideo.src = videoUrl;
                hiddenVideo.currentTime = 1; // Start slightly in
                
                // Add to media items for preview
                mediaItems.push({ type: 'video', content: videoUrl });

                let framesCaptured = 0;
                const targetFrames = 3;
                const captures = [];

                const onSeeked = () => {
                    // Draw to canvas
                    hiddenCanvas.width = hiddenVideo.videoWidth;
                    hiddenCanvas.height = hiddenVideo.videoHeight;
                    const ctx = hiddenCanvas.getContext('2d');
                    ctx.drawImage(hiddenVideo, 0, 0, hiddenCanvas.width, hiddenCanvas.height);
                    
                    // Compress to jpeg
                    const dataUrl = hiddenCanvas.toDataURL('image/jpeg', 0.7);
                    captures.push(dataUrl);
                    framesCaptured++;

                    if (framesCaptured < targetFrames) {
                        // Seek to next position (30%, 60%, 90%)
                        const nextTime = hiddenVideo.duration * ((framesCaptured + 1) * 0.3);
                        if (nextTime < hiddenVideo.duration) {
                            hiddenVideo.currentTime = nextTime;
                        } else {
                            finish();
                        }
                    } else {
                        finish();
                    }
                };

                const finish = () => {
                    hiddenVideo.removeEventListener('seeked', onSeeked);
                    extractedFrames.push(...captures);
                    videoFramesInfo.classList.remove('hidden');
                    if (revokeUrl) URL.revokeObjectURL(videoUrl);
                    resolve();
                };

                hiddenVideo.addEventListener('loadedmetadata', () => {
                    if(hiddenVideo.duration === Infinity || isNaN(hiddenVideo.duration)) {
                        // Streaming or unknown duration, just take one frame
                        hiddenVideo.currentTime = 0;
                    } else {
                        hiddenVideo.currentTime = hiddenVideo.duration * 0.1;
                    }
                });

                hiddenVideo.addEventListener('seeked', onSeeked);
                
                const urlObj = new URL(videoUrl, window.location.href);
                
                hiddenVideo.addEventListener('error', (e) => {
                    console.error('Video Error:', hiddenVideo.error);
                    let msg = "無法載入影片。";
                    if (hiddenVideo.error && hiddenVideo.error.code === 4) {
                         msg += " (格式不支援或來源無法存取)";
                    } else if (urlObj && urlObj.origin !== window.location.origin) {
                        msg += " 可能涉及跨域 (CORS) 問題，請確保該影片伺服器允許跨域存取。";
                    }
                    alert(msg + "\n\n建議: 請嘗試下載該影片並使用「拖放上傳」功能。");
                    resolve(); // Resolve anyway to not break flow
                });
            });
        }

        function updatePreview() {
            if (mediaItems.length > 0) {
                previewArea.classList.remove('hidden');
                mediaContainer.innerHTML = '';
                mediaItems.forEach(item => {
                    if (item.type === 'image') {
                        const img = document.createElement('img');
                        img.src = item.content;
                        img.className = 'h-48 object-contain rounded border border-gray-300';
                        mediaContainer.appendChild(img);
                    } else if (item.type === 'video') {
                        const vid = document.createElement('video');
                        vid.src = item.content;
                        vid.controls = true;
                        vid.className = 'h-48 max-w-full rounded border border-gray-300';
                        mediaContainer.appendChild(vid);
                    }
                });
            }
        }

        async function startAnalysis(isAuto = false) {
            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                alert('請輸入 OpenRouter API Key');
                // Stop loop if no key
                if (autoLoopInterval) stopLoopBtn.click();
                return;
            }
            if (extractedFrames.length === 0) {
                if (!isAuto) alert('請先上傳圖片或影片');
                return;
            }

            resultSection.classList.remove('hidden');
            loadingIndicator.classList.remove('hidden');
            outputContent.innerHTML = '';
            analyzeBtn.disabled = true;

            try {
                const model = document.getElementById('modelName').value;
                
                // Construct payload
                const content = [
                    {
                        type: "text",
                        text: `Please analyze the image and provide a JSON response (without markdown code blocks) with the following structure:
{
  "english_sentence": "A simple KET A2 level English sentence (10-20 words) describing the image.",
  "chinese_translation": "The Traditional Chinese (繁體中文) translation of the above sentence."
}
Ensure the content is strictly KET A2 level and all Chinese text is in Traditional Chinese (繁體中文).`
                    }
                ];

                // Add images
                extractedFrames.forEach(frameData => {
                    content.push({
                        type: "image_url",
                        image_url: {
                            url: frameData
                        }
                    });
                });

                const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${apiKey}`,
                        "Content-Type": "application/json",
                        "HTTP-Referer": window.location.href, // Required by OpenRouter
                        "X-Title": "Media Analyzer Tool"
                    },
                    body: JSON.stringify({
                        model: model,
                        temperature: 0.3,
                        messages: [
                            {
                                role: "user",
                                content: content
                            }
                        ]
                    })
                });

                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.error?.message || 'API Request failed');
                }

                const data = await response.json();
                console.log('API Response:', data);

                if (!data.choices || data.choices.length === 0) {
                    throw new Error('API 返回了意外的格式（缺少 choices 字段）。請檢查控制台日誌以獲取更多詳情。\n\n完整響應: ' + JSON.stringify(data, null, 2));
                }

                const responseData = data.choices[0].message.content;
                let parsedData;
                try {
                    // Improved JSON extraction: find the first '{' and last '}'
                    const firstBrace = responseData.indexOf('{');
                    const lastBrace = responseData.lastIndexOf('}');
                    
                    let jsonStr;
                    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {
                         jsonStr = responseData.substring(firstBrace, lastBrace + 1);
                    } else {
                         // Fallback to basic cleaning if braces not found
                         jsonStr = responseData.replace(/```json/g, '').replace(/```/g, '').trim();
                    }
                    
                    parsedData = JSON.parse(jsonStr);

                } catch (e) {
                    console.error("JSON Parse Error", e);
                    // Fallback if not JSON
                    // Try to extract english sentence via Regex if JSON parse failed
                    const engMatch = responseData.match(/"english_sentence":\s*"([^"]+)"/);
                    const engSentence = engMatch ? engMatch[1] : (responseData.length > 200 ? "Analysis failed to parse." : responseData);

                    parsedData = {
                        english_sentence: engSentence,
                        chinese_translation: "解析格式錯誤，請查看下方原始資料。"
                    };
                    
                    // Show raw response for debugging in a collapsed details
                    parsedData.chinese_translation += `<br><details><summary class="cursor-pointer text-blue-500">原始回覆 (Raw Response)</summary><pre class="text-xs whitespace-pre-wrap mt-2 text-gray-500">${responseData.replace(/</g, '&lt;')}</pre></details>`;
                }

                // Render UI
                const html = `
                    <div class="bg-blue-50 p-6 md:p-10 rounded-2xl border border-blue-100 text-center space-y-8 shadow-inner">
                        <div class="space-y-2">
                            <p class="text-4xl md:text-5xl text-blue-900 font-bold leading-tight tracking-tight">${parsedData.english_sentence}</p>
                        </div>
                        
                        <div class="border-t-2 border-blue-200 w-1/2 mx-auto"></div>
                        
                        <div class="space-y-2">
                            <p class="text-3xl md:text-4xl text-gray-700 font-medium leading-relaxed">${parsedData.chinese_translation}</p>
                        </div>
                    </div>
                `;
                
                outputContent.innerHTML = html;
                
                // Add Speak Button
                const speakBtn = document.createElement('button');
                speakBtn.className = "mt-6 bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-6 rounded-full shadow flex items-center mx-auto transition transform hover:scale-105";
                speakBtn.innerHTML = `<svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z"></path></svg> 再次朗讀英文`;
                speakBtn.onclick = () => {
                    // Clear previous queue to avoid stacking too many if clicked multiple times
                    clearTTS(); 
                    for(let i=0; i<3; i++) speakText(parsedData.english_sentence);
                };
                outputContent.appendChild(speakBtn);

                // Auto speak English only
                clearTTS(); // Clear previous queue and stop speaking before new one
                for(let i=0; i<3; i++) {
                    speakText(parsedData.english_sentence);
                }

            } catch (error) {
                console.error(error);
                outputContent.innerHTML = `<div class="text-red-600 bg-red-50 p-4 rounded overflow-auto"><p class="font-bold">發生錯誤:</p><pre class="whitespace-pre-wrap text-xs mt-2">${error.message}</pre></div>`;
            } finally {
                loadingIndicator.classList.add('hidden');
                analyzeBtn.disabled = false;
            }
        }

        function clearTTS() {
            ttsQueue = [];
            ttsActive = false;
            currentUtterance = null;
            if ('speechSynthesis' in window) {
                window.speechSynthesis.cancel();
            }
        }

        function speakText(text) {
            if (!('speechSynthesis' in window)) {
                alert("您的瀏覽器不支援語音合成功能。");
                return;
            }
            if (!text) return;

            // Remove Chinese characters and Chinese punctuation to ensure only English is spoken
            const cleanText = text.replace(/[\u4e00-\u9fa5\u3000-\u303f\uff00-\uffef]/g, '').trim();

            if (!cleanText) return;

            ttsQueue.push(cleanText);

            // Recovery check: if active but not speaking, force reset
            if (ttsActive && !window.speechSynthesis.speaking && !window.speechSynthesis.pending) {
                 ttsActive = false;
            }

            if (!ttsActive) {
                const next = () => {
                    if (ttsQueue.length === 0) {
                        ttsActive = false;
                        currentUtterance = null;
                        return;
                    }
                    ttsActive = true;
                    const t = ttsQueue.shift();
                    const utterance = new SpeechSynthesisUtterance(t);
                    currentUtterance = utterance; // Keep reference to prevent GC
                    
                    utterance.lang = 'en-US';
                    utterance.rate = 0.9;
                    utterance.onend = () => {
                        ttsActive = false;
                        next();
                    };
                    utterance.onerror = (e) => {
                        console.error("TTS Error:", e);
                        ttsActive = false;
                        next();
                    };
                    window.speechSynthesis.speak(utterance);
                };
                next();
            }
        }
    </script>
</body>
</html>
